{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "I1ro7GlckN5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a298232-3058-4b35-cf64-1d50b28abac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m266.2/328.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m931.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='')\n",
        "import pandas as pd\n",
        "from tenacity import *\n",
        "import re"
      ],
      "metadata": {
        "id": "R6rgZG9KTaSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a system message for GPT.\n",
        "system_message = \"You are a drug consultant.\"\n",
        "gpt_model_params = {\n",
        "    \"model\": \"gpt-4o\",\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 0,\n",
        "    \"presence_penalty\": 0,\n",
        "    \"frequency_penalty\": 0\n",
        "}\n",
        "\n",
        "# For user messages, define the size of medical entity batches to avoid exceeding GPT's response limits.\n",
        "batch_size = 140"
      ],
      "metadata": {
        "id": "PKULw9MykaYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the clean list of medical entities generated from extract_medical_entities.ipynb.\n",
        "med_ents = pd.read_excel('med_ents_detailed_TM.xlsx')\n",
        "med_ents"
      ],
      "metadata": {
        "id": "C9FsPkiX7yaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_batches(data, batch_size):\n",
        "    keys = list(data.keys())\n",
        "    batches = []\n",
        "    for i in range(0, len(keys), batch_size):\n",
        "        batch_keys = keys[i:i + batch_size]\n",
        "        batch = {key: data[key] for key in batch_keys}\n",
        "        batches.append(batch)\n",
        "    return batches"
      ],
      "metadata": {
        "id": "zAoKiVX51QMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_json(df):\n",
        "    JSON_input = {}\n",
        "    for i in range(0, df.shape[0]):\n",
        "        JSON_input[i] = df.loc[i, 'med_ents']\n",
        "    return(JSON_input)"
      ],
      "metadata": {
        "id": "CGxzlP1m1Rv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_message(batch):\n",
        "    i = 0\n",
        "    user_message = f\"\"\"You receive a list of various terms, but you need only drug trade names on it. Your task for them is to specify their:\n",
        "- manufacturer\n",
        "- international non-proprietary names\n",
        "- indications (diseases only)\n",
        "- group of diseases, which includes the diseases from the indications for the use of drugs\n",
        "If there is no trade name in the list, response 'None'.\n",
        "\n",
        "The format of the answer should be as follows:\n",
        "0. manufacturer : trade name : international non-proprietary name (INN) : indications : group of diseases\n",
        "1. manufacturer : trade name : international non-proprietary name (INN) : indications : group of diseases\n",
        "\n",
        "List of terms:\"\"\"\n",
        "    for key in batch.keys():\n",
        "        user_message = \"\"\"{0}\\n{1}. {2}\"\"\".format(user_message, i, batch[key])\n",
        "        i += 1\n",
        "    return user_message"
      ],
      "metadata": {
        "id": "NIAjMl-p4Gpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@retry(stop=stop_after_attempt(3), wait=wait_fixed(300))\n",
        "def completion_with_backoff(**kwargs):\n",
        "    return client.chat.completions.create(**kwargs).choices[0].message.content"
      ],
      "metadata": {
        "id": "yM0a1FX150iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_portfolio(JSON_segments, batch_size, system_message):\n",
        "    full_portfolio = []\n",
        "    data = JSON_segments\n",
        "    batches = create_batches(data, batch_size)\n",
        "    batch_num = 1\n",
        "    for batch in batches:\n",
        "        batch_index_list = list(batch.keys())\n",
        "        user_message = create_user_message(batch)\n",
        "        message = [\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "        print(message)\n",
        "        try:\n",
        "            portfolio_part = completion_with_backoff(messages=message, **gpt_model_params)\n",
        "            full_portfolio.extend(list(filter(None, portfolio_part.split('\\n'))))\n",
        "        except Exception as e:\n",
        "            print('Batch error!' + str(batch_num), e)\n",
        "            pass\n",
        "        batch_num += 1\n",
        "    result = [re.sub(r'^[0-9]+\\. ', '', i) for i in full_portfolio]\n",
        "    return result"
      ],
      "metadata": {
        "id": "FzEebCrA53ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data, send requests to GPT, and save the responses for each batch.\n",
        "JSON_input = create_json(med_ents)\n",
        "output = compile_portfolio(JSON_input, batch_size, system_message)"
      ],
      "metadata": {
        "id": "DQeAHiia6zNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out responses that do not match the required format, then split valid responses by \" : \".\n",
        "clean_list_of_responses = []\n",
        "\n",
        "for response in output:\n",
        "  if response.count(' : ') == 4:\n",
        "    row = response.split(' : ')\n",
        "    clean_list_of_responses.append(row)"
      ],
      "metadata": {
        "id": "qik1B-9BH4D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile a portfolio with the necessary columns and remove duplicates based on the Trade name column.\n",
        "drug_portfolio = pd.DataFrame(clean_list_of_responses, columns = [\"Manufacturer\", \"Trade name\", \"INN\", \"Indications\", \"Group of diseases\"])\n",
        "drug_portfolio.drop_duplicates(subset=[\"Trade name\"])"
      ],
      "metadata": {
        "id": "D9U6Z9a7BQTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drug_portfolio.to_excel('drug_portfolio.xlsx', index = False)"
      ],
      "metadata": {
        "id": "o7ykPTUleERt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}